# Supervised Learning

Owner: Prem kumar Ganji

## Types of Supervised Learning

### **Classification**

**Classification** is the process of finding or discovering a model or function that helps in separating the data into multiple categorical classes i.e. discrete values.

- Predict categories, small number of possible outcomes

**Common Algorithms**

- Logistic Regression
- Decision Trees
- Support Vector Machines (SVM)
- Random Forest
- Neural Networks
- Naive Bayes

### Regression

**Regression** is the process of finding a model or function for distinguishing the data into continuous real values instead of using classes or discrete values.

- Predict a number, infinite many possible outcomes

**Common Algorithms**

- Linear Regression
- Polynomial Regression
- Support Vector Regression (SVR)
- Decision Tree Regression
- Random Forest Regression
- Neural Networks (for regression tasks)

# Linear Regression

**Linear regression** is a statistical method used in supervised learning to model the relationship between one or more input features (independent variables) and a continuous output (dependent variable). 

The primary goal of linear regression is to find the best-fitting linear equation that predicts the output variable based on the input variables.

## Types

### 1. Simple Linear Regression

This involves only one input feature. The relationship between the input (X) and output (Y) is modeled as a straight line:

```sql
Y=b0+b1X
```

Where:

- Y is the predicted output (dependent variable).
- X is the input (independent variable).
- b0 is the y-intercept (the point where the line crosses the y-axis).
- b1 is the slope of the line, representing the change in Y for a unit change in X.

### 2. Multiple Linear Regression

When there are multiple input features, the equation is extended to:

```sql
Y=b0+b1X1+b2X2+ ... +bnXn
```

Where:

- X1,X2,…,Xn are the input features (independent variables).
- b1,b2,…,bn are the coefficients that represent the impact of each feature on the output.