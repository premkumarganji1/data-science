# Cost Function

Owner: Prem kumar Ganji

https://medium.com/@yennhi95zz/3-understanding-the-cost-function-in-linear-regression-for-machine-learning-beginners-ec9edeecbdde

# **Defining the Cost Function**

When working with linear regression, we aim to find the best line that fits the training data. ***The cost function measures the difference between the predicted values of the model and the actual target values***. By minimizing this cost function, we can determine the optimal values for the model’s parameters and improve its performance.

## Formula

![image.png](Cost%20Function%2010656645436280a7ae14f3d23fe77b87/image.png)

***where:***

![https://miro.medium.com/v2/resize:fit:324/1*LvxUw8wkp7giKP_jVGufgw.png](https://miro.medium.com/v2/resize:fit:324/1*LvxUw8wkp7giKP_jVGufgw.png)

# **Understanding the Parameters**

The parameters w and b have a significant impact on the shape and position of the line in the graph. Different values of w and b lead to different lines with varying slopes and intercepts. By adjusting these parameters during training, we can optimize the line to better fit the data.

# **Intuition Behind the Cost Function**

The cost function, denoted as `J(w, b)`, measures how well the model’s predictions align with the true target values. It calculates the squared error between the predicted value (`f(w, b, x)`) and the actual target value (`y`). The cost function is defined as the sum of squared errors across all training examples, and its value indicates how well the model fits the data.

- Notes of Cost Function
    
    [cost function.pdf](Cost%20Function%2010656645436280a7ae14f3d23fe77b87/cost_function.pdf)